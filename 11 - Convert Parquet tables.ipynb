{"cells":[{"cell_type":"markdown","source":["# Convert Parquet table to Delta table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2e8f3179-08d9-44fd-ac83-0e89ff253d01"},{"cell_type":"code","source":["# Generate dummy data\n","\n","from pyspark.sql.functions import expr, lit, col\n","from pyspark.sql.types import *\n","from datetime import date\n","\n","\n","df = spark.range(5) \\\n","  .selectExpr(\"if(id % 2 = 0, 'Open', 'Close') as action\") \\\n","  .withColumn(\"date\", expr(\"cast(concat('2023-06-', cast(rand(5) * 30 as int) + 1) as date)\")) \\\n","  .withColumn(\"device_id\", expr(\"cast(rand(5) * 100 as int)\"))\n","\n","# Registering a Parquet table in the catalog\n","parquet_table_name = 'demo.device'\n","spark.sql(f\"DROP TABLE IF EXISTS {parquet_table_name}\")\n","\n","df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(parquet_table_name)"],"outputs":[],"execution_count":null,"metadata":{},"id":"cccbf60e-b1c4-4e79-8703-aba9dbaf9ab3"},{"cell_type":"markdown","source":["Let's take a look at the table. You can see that the icon is different in the lakehouse explorer under tables section and pay attention to provider (line 13) "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bdf6dc54-f49f-4098-9381-86afe5b2390c"},{"cell_type":"code","source":["%%sql\n","\n","DESCRIBE EXTENDED demo.device\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"f15c3cbb-afbc-487e-ac1a-18b16e16d383"},{"cell_type":"markdown","source":["## Converting to Delta table\n","\n","You can use CONVERT TO DELTA to transform a directory of Parquet files into a Delta table with a single command. Once you have converted a table to Delta Lake, you should stop reading and writing from the table using Parquet logic.\n","The code is simple and the Parquet files don't need to be rewritten, so it requires fewer computational resources than you might imagine"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6553890a-2db2-4151-859c-309dcc4e8089"},{"cell_type":"code","source":["from delta.tables import *\n","\n","deltaTable = DeltaTable.convertToDelta(spark, \"demo.device\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"editable":true,"run_control":{"frozen":false}},"id":"8d22b3ce-2417-48d4-825d-74e757f1b3b4"},{"cell_type":"code","source":["%%sql\n","\n","CONVERT TO DELTA demo.device"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"6f00aa98-6a67-42d8-b535-c0555a9c8c74"},{"cell_type":"markdown","source":["Note that the icon on the lakehouse explorer and the provider (line 11) have changed"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"67fea265-3212-4fc2-ac61-a5e6928064ae"},{"cell_type":"code","source":["%%sql\n","\n","DESCRIBE EXTENDED demo.device\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"6a7036dc-892c-476d-a8d2-4d045d232288"},{"cell_type":"code","source":["df = spark.range(100) \\\n","  .selectExpr(\"if(id % 2 = 0, 'Open', 'Close') as action\") \\\n","  .withColumn(\"date\", expr(\"cast(concat('2023-06-', cast(rand(5) * 30 as int) + 1) as date)\")) \\\n","  .withColumn(\"device_id\", expr(\"cast(rand(5) * 100 as int)\"))\n","\n","\n","parquet_table_name = 'demo.device_partitioned'\n","\n","spark.sql(\"DROP TABLE IF EXISTS \" + parquet_table_name)\n","df.write.format(\"parquet\").partitionBy(\"date\").mode(\"overwrite\").saveAsTable(parquet_table_name)"],"outputs":[],"execution_count":null,"metadata":{},"id":"081f366b-25da-49f2-8003-acb18726f36e"},{"cell_type":"code","source":["%%sql\n","\n","DESCRIBE EXTENDED demo.device_partitioned"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"e2b79972-75fe-4bcb-a27c-355a0a6d4ba0"},{"cell_type":"code","source":["from delta.tables import *\n","\n","deltaTable = DeltaTable. convertToDelta(spark, \"demo.device_partitioned\", \"date date\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"editable":false,"run_control":{"frozen":true}},"id":"0850b95a-2046-4ddb-9e93-fb67d07fe7da"},{"cell_type":"code","source":["%%sql\n","\n","CONVERT TO DELTA demo.device_partitioned PARTITIONED BY (date date)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"a051d6f8-d389-4124-9b9a-6308fb1c08a8"},{"cell_type":"code","source":["%%sql\n","\n","DESCRIBE EXTENDED demo.device_partitioned"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"6185626c-e012-4946-9e0d-9bc63277a6dd"},{"cell_type":"markdown","source":["# Clean up"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"16544446-31be-4765-89de-5ebab39d6abf"},{"cell_type":"code","source":["spark.sql(\"DROP TABLE IF EXISTS device\")\n","spark.sql(\"DROP TABLE IF EXISTS device_partitioned\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5ca86362-f08e-4542-902e-c75286ad9e0f"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"notebook_environment":{},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}